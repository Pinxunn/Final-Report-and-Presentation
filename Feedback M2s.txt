Automatic training set generation for improved fake news detection
AUTHORS: Namuwonge Hedwig Naava

----------- Overall evaluation -----------
SCORE: -1 (weak reject)
----- TEXT:
Style and orthography: 0
-The paper follows the guidelines (ACL template & page limit): 0
-Spelling and grammar mistakes: 0
-The citations and references follow the same format throughout the paper: 0

Structure and cohesion total possible: 3
-The paper’s title corresponds to the content of the paper: 1
-The sections of the paper are linked clearly: 0
-The paper introduces the researched problem and the background clearly: 0.5
-The paper discusses the previous research relevant to the problem:1.5
-The paper derives a clear conclusion from the research:0

Experiment and results total possible: 1
-The experiment setup is discussed clearly, all the resources to reproduce the experiment are given : 1
-The evaluation of the experiment is discussed clearly: 0 
-The results of the experiments are provided with the evaluation: 0
-The results are commented and discussed: 0
-The further work is discussed:0

Total score : 4


This paper is incomplete and unstructured. There are some spelling mistakes, typos, irregularities, and different types of citations used, plus, some citations are not official in a scientific paper.  All the concepts first introduced in the paper should be explained in order to be understood (e.g. you mention you use Llama-2 but without any explanation before section 7. "LDTTRc and LDHDD", we don't understand these informations without some more explanations). You should  also pay more attention to the link between each section. The structure of your paper should be redefined. Maybe Section 2 and Section 3 could be merged together. Section 5.1 is way too long, and is the unique subsection to Section 5, which indicates a structural problem (and, in our opinion, data analysis should not be a subsection of dataset description). Section 6 is not informative (there is no use in mentioning parameters without their values). Section 7 has too many (repetitive) subsections, and shoul
d not come so late in the paper. Your paper lacks results, discussion, description of the evaluation, and a conclusion. Despite these remarks, we acknowledge important and interesting work in Section 5.1. If you take the above  remarks into consideration in your future work, we encourage you  and believe that you will improve in your next paper.



----------------------- REVIEW 2 ---------------------
SUBMISSION: 10
TITLE: Automatic training set generation for improved fake news detection
AUTHORS: Namuwonge Hedwig Naava

----------- Overall evaluation -----------
SCORE: -2 (reject)
----- TEXT:
Article Structure:

  - You should really focus on how you organize your text in paragraphs. For example with the introduction: “This report delves into the development, evaluation, and impact of a fake news detection and generation model. In modern natural language processing, pre-training has become the standard approach.” You should use the first sentence to conclude the first paragraph and start a new paragraph with the second sentence.
  - The introduction footnote could be a proper paragraph.
  - Section 3 is dropped out of nowhere. There is no explanation of why you mention it. Same for FRE, how does it work? Do you use it? Why?
  - You mention TopicBERT, did you use it? It seems not, the paragraph which talks about it, although interesting, does not seem to have its place in the paper.
  - Section 6 is irrelevant, explaining that you use the “from_pretrained” function or that deep learning models are trained using a backpropagation algorithm is too much. You should focus on section 7.
  - “The model is evaluated on the validation dataset and can be further fine-tuned if it doesn’t perform well”. This is not the purpose of a validation set.
  - About section 7, it is a good thing to explain how the original model was trained and on which data but you should focus on your usage and how you finetune them. Also, you should describe which metrics you will use to evaluate your model, especially for the Llama-2 experiment where it seems difficult to provide a good evaluation of your results.
  - No results, no discussion about them and no conclusion.

Citation:
  - At least Llama-2 and roBERTA are not cited.
  - The work of OpenAI on emission for 2040 is not cited.

Data analysis:
  - Your analysis is confusing. Why not compare the distributions directly rather than use a Shapiro-Wilk test and then compare the distributions? The Mann–Whitney U test (nonparametric test to check whether two distributions are similar), Student's t-test (parametric test to check whether two samples have similar average values), Welch's t-test (nonparametric version of Student’s t-test) or Kolmogorov–Smirnov test (nonparametric to compare the distributions of two samples) seem more appropriate.

Overall:
  - It is difficult to review a paper that is not complete. You should have focused on the finished parts of your project. It's not even worth mentioning finetuning if you don't show the results. You should place them in a “future works” section and conclude your paper with the work already done. You should also be careful about missing citations. 
  - It is a very good thing that you share your code in the paper. We can criticize the absence of a README clearly explaining how the repository is structured. But we'd rather you share this than nothing at all.



----------------------- REVIEW 3 ---------------------
SUBMISSION: 10
TITLE: Automatic training set generation for improved fake news detection
AUTHORS: Namuwonge Hedwig Naava

----------- Overall evaluation -----------
SCORE: -2 (reject)
----- TEXT:
Even if the subject of your article is really interesting and could bring a lot to the field, we had to reject you paper for the following reasons :

--> your paper doesn't follow the ACL guidelines, contains a lot of mistakes and citations format errors
--> your research question and your reasoning behind it is not clear, in what way generating fake news will help you detecting it ?
--> the methodology and datasets parts missed a lot of information needed to reproduce it, a lot of datasets are not properly presented, the github is hidden and do not contains a README, your features are not properly presented
--> the papers contains no evaluation, no results or discussion. If no results are found yet, a discussion of what results you expect and what does this results would mean is required
--> the previous work is not detailed enough, this missing information make it harder to understand what you are doing