{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the json encoder for np arrays\n",
    "from json import JSONEncoder\n",
    "import json\n",
    "import numpy\n",
    "\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, numpy.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "import joblib\n",
    "\n",
    "\n",
    "def data_preprocess(data):\n",
    "  '''We input the data with the linguistic features\n",
    "  And it returns the data with the polarity columns in 0 for fake and 1 for true\n",
    "  as well as the outcomes\n",
    "  '''\n",
    "\n",
    "  if data.Polarity[0] != 0 or 1:\n",
    "    data.Polarity[data.Polarity == 'Fake'] = 0\n",
    "    data.Polarity[data.Polarity == 'True'] = 1\n",
    "\n",
    "  outcomes = [\"Fake\",\"Real\"]\n",
    "  # print(\"unique Polairty labels:\", data.Polarity.unique())\n",
    "\n",
    "  return data, outcomes\n",
    "\n",
    "\n",
    "def test_train(data, features):\n",
    "\n",
    "  '''We input the data with the features and a list of the features we want to pass to the models.\n",
    "  it returns the data split in test/train\n",
    "  '''\n",
    "\n",
    "  data = data.dropna()\n",
    "  feature_cols = features\n",
    "\n",
    "\n",
    "\n",
    "  X = data[feature_cols]\n",
    "  y = data.Polarity #outcomes 0 or 1\n",
    "  y_ref= \"Polarity\"\n",
    "\n",
    "  print(\"Info: {} features were passed at the fit step\\n:\".format(X.shape[1]))\n",
    "  for feature in feature_cols:\n",
    "    print(feature)\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=16)\n",
    "\n",
    "  return X, y, X_train, X_test, y_train, y_test, features, y_ref\n",
    "\n",
    "  #stratify so that the proportion of the train data is the same for fake and true\n",
    "\n",
    "\n",
    "def class_report(y_test, y_pred):\n",
    "\n",
    "  outcomes = [\"Fake\",\"Real\"]\n",
    "\n",
    "  scores = classification_report(y_test, y_pred, target_names=outcomes)\n",
    "\n",
    "  print(scores)\n",
    "\n",
    "  return scores\n",
    "\n",
    "def compare_models_cross_val(model, X, y):\n",
    "  '''for each model, it calculates the cross validation accuracy for each iteration\n",
    "  as well as the mean cross validation score on the given data\n",
    "\n",
    "  '''\n",
    "\n",
    "  print(\"CROSS VALIDATION\\n\")\n",
    "\n",
    "  model_name = str(model)[:-2]\n",
    "\n",
    "  if model_name == \"SVC(kernel=\\'linear\":\n",
    "\n",
    "    model_name = \"SVC\"\n",
    "\n",
    "\n",
    "  # for model in models:\n",
    "  cv_score = cross_val_score(model, X, y, cv = 5)\n",
    "  print(\"Accuracy {} for each of the 5 iterations:\".format(model_name))\n",
    "  for score in cv_score:\n",
    "    print(round(score*100, 2), \"%\")\n",
    "\n",
    "  mean_accuracy = sum(cv_score)/len(cv_score)\n",
    "\n",
    "  print(\"\\nCross validation mean accuracy for {}:\".format(model_name), round(mean_accuracy*100, 2),\"%\")\n",
    "  print(\"\\n-------------------------------------------------------------------------\\n\")\n",
    "\n",
    "  return cv_score, mean_accuracy\n",
    "\n",
    "def conf_matrix(model_name, features, y_pred, y_test, cmap=\"magma\"):\n",
    "\n",
    "  '''This function takes the predicted and test labels, generates the confusion matrix\n",
    "  and displays it\n",
    "  '''\n",
    "\n",
    "  n_features = len(features)\n",
    "\n",
    "  confussion_matrix = confusion_matrix(y_pred, y_test)\n",
    "\n",
    "  outcomes = [\"Fake\",\"Real\"]\n",
    "  ticks = np.arange(len(outcomes))\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  plt.xticks(ticks, outcomes)\n",
    "  plt.yticks(ticks, outcomes)\n",
    "  sns.heatmap(pd.DataFrame(confussion_matrix), annot=True, cmap=cmap, fmt=\"g\", xticklabels=outcomes, yticklabels=outcomes)\n",
    "  ax.xaxis.set_label_position(\"top\")\n",
    "  plt.tight_layout()\n",
    "  if n_features == 1:\n",
    "\n",
    "    plt.title(\"{} Confusion Matrix: {}\".format(model_name, features[0]), y = 1.1)\n",
    "\n",
    "  elif n_features == 2:\n",
    "\n",
    "    plt.title(\"{} Confusion Matrix: {} and {}\".format(model_name, features[0],features[1]), y = 1.1)\n",
    "\n",
    "  elif n_features == 3:\n",
    "\n",
    "    plt.title(\"{} Confusion Matrix: {}, {} and {}\".format(model_name, features[0],features[1], features[2]), y = 1.1)\n",
    "\n",
    "  plt.ylabel(\"Actual label\")\n",
    "  plt.xlabel(\"Predicted label\")\n",
    "\n",
    "  return confussion_matrix\n",
    "\n",
    "def compare_models_train_test_split(models, X, y, X_train, y_train, X_test, y_test, features, y_ref):\n",
    "\n",
    "  '''this fx trains the data on the four types of models,\n",
    "  generates a report with the overall accuracy of the model, the cross validation evaluation\n",
    "  and prints the confussion matrix of each model on the particular test_train split.\n",
    "\n",
    "  It returns a dictionary with the name of the model, the features that were passed during the fit,\n",
    "  the model used, the accuracy score, the classification report, the crossvalidation evaluation and the confusion matrix\n",
    "  '''\n",
    "\n",
    "  model_list_dicts =[]\n",
    "\n",
    "  for model in models:\n",
    "\n",
    "    model_name = str(model)[:-2]\n",
    "\n",
    "    if model_name == \"SVC(kernel=\\'linear\":\n",
    "\n",
    "      model_name = \"SVC\"\n",
    "\n",
    "    model_dict = {}\n",
    "\n",
    "    ft_str = str(features)[2:-2].replace(\"'\",\"_\").replace(\",\", \"_\").replace(\" \", \"_\").replace(\"___\", \"_\")\n",
    "\n",
    "    model_dict[\"name\"] = ft_str + \"__\" + model_name\n",
    "\n",
    "    model_dict[\"features\"] = features\n",
    "\n",
    "    model_dict[\"model\"] = model_name\n",
    "\n",
    "    print(\"\\n\",model_name, \"\\n\", \"\\n\")\n",
    "\n",
    "    model = model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    model_dict[\"accuracy\"] = accuracy\n",
    "\n",
    "    print(\"OVERALL ACCURACY\", model_name, \":\", round(accuracy*100, 2),\"%\"\"\\n\")\n",
    "\n",
    "\n",
    "    scores = class_report(y_test, y_pred)\n",
    "\n",
    "    model_dict[\"report\"] = scores\n",
    "\n",
    "    # print(scores)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    cv_score, mean_accuracy = compare_models_cross_val(model, X, y)\n",
    "\n",
    "    model_dict[\"cv_scores\"] = cv_score\n",
    "\n",
    "    model_dict[\"mean_cv_accuracy\"] = mean_accuracy\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    confussion_matrix = conf_matrix(model_name, features, y_pred, y_test, cmap=\"magma\")\n",
    "\n",
    "    model_dict[\"confussion_matrix\"] = confussion_matrix\n",
    "\n",
    "    model_list_dicts.append(model_dict)\n",
    "    \n",
    "    joblib.dump(value=[model, features, y_ref], filename=r\"C:\\Users\\alber\\Desktop\\Make Believe Diciembre\\Models\\{}.pkl\".format(ft_str + \"__\" + model_name))\n",
    "  \n",
    "  with open(r\"C:\\Users\\alber\\Desktop\\Make Believe Diciembre\\Models\\Info Dictionaries\\{}.json\".format(ft_str), \"w\") as f:\n",
    "    json.dump(model_list_dicts, f, cls=NumpyArrayEncoder)\n",
    "  \n",
    "  \n",
    "  return model_list_dicts\n",
    "\n",
    "def magic(data, features):\n",
    "\n",
    "  '''this function takes all the previous functions and integrates them into a single function to run the data processing, training and testing in all the models.\n",
    "\n",
    "  It returns a dictionary with the name of the model, the features that were passed during the fit,\n",
    "  the model used, the accuracy score, the classification report, the crossvalidation evaluation and the confusion matrix\n",
    "\n",
    "  '''\n",
    "\n",
    "  data, outcomes = data_preprocess(data) # data in the correct format for the y outcomes\n",
    "\n",
    "  X, y, X_train, X_test, y_train, y_test, features, y_ref = test_train(data, features) # here we have the data split for all the models with the desired features\n",
    "\n",
    "  model_list_dicts = compare_models_train_test_split(models, X, y, X_train, y_train, X_test, y_test, features, y_ref) # for each model it will compute\n",
    "\n",
    "  return model_list_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fts = pd.read_csv(r\"C:\\Users\\alber\\Desktop\\Make Believe Diciembre\\all_ling_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>DESPC</th>\n",
       "      <th>DESSC</th>\n",
       "      <th>DESWC</th>\n",
       "      <th>DESPL</th>\n",
       "      <th>DESPLd</th>\n",
       "      <th>DESPLw</th>\n",
       "      <th>DESSL</th>\n",
       "      <th>DESSLd</th>\n",
       "      <th>DESWLsy</th>\n",
       "      <th>...</th>\n",
       "      <th>WORD_PROPERTY_WRDHYPn</th>\n",
       "      <th>WORD_PROPERTY_WRDHYPv</th>\n",
       "      <th>WORD_PROPERTY_WRDHYPnv</th>\n",
       "      <th>WORD_PROPERTY_AOA</th>\n",
       "      <th>WORD_PROPERTY_AOA_MAX</th>\n",
       "      <th>WORD_PROPERTY_CONCRETENESS</th>\n",
       "      <th>WORD_PROPERTY_PREVALENCE</th>\n",
       "      <th>WORD_PROPERTY_PREVALENCE_MIN</th>\n",
       "      <th>WORD_SET_INCIDENCE_C4_COMMON_WORDS</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.903743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244583</td>\n",
       "      <td>0.283489</td>\n",
       "      <td>0.388215</td>\n",
       "      <td>0.687937</td>\n",
       "      <td>0.396186</td>\n",
       "      <td>0.434696</td>\n",
       "      <td>0.637852</td>\n",
       "      <td>0.637852</td>\n",
       "      <td>0.685198</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.325123</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.157542</td>\n",
       "      <td>0.331016</td>\n",
       "      <td>0.509944</td>\n",
       "      <td>0.109532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267995</td>\n",
       "      <td>0.338908</td>\n",
       "      <td>0.076927</td>\n",
       "      <td>0.051748</td>\n",
       "      <td>0.309322</td>\n",
       "      <td>0.676325</td>\n",
       "      <td>0.646687</td>\n",
       "      <td>0.646687</td>\n",
       "      <td>0.252618</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.354680</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.177654</td>\n",
       "      <td>0.254011</td>\n",
       "      <td>0.442546</td>\n",
       "      <td>0.199330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471208</td>\n",
       "      <td>0.183434</td>\n",
       "      <td>0.469044</td>\n",
       "      <td>0.238065</td>\n",
       "      <td>0.297608</td>\n",
       "      <td>0.756879</td>\n",
       "      <td>0.615946</td>\n",
       "      <td>0.615946</td>\n",
       "      <td>0.546360</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012552</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.394089</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.197765</td>\n",
       "      <td>0.398396</td>\n",
       "      <td>0.388716</td>\n",
       "      <td>0.191279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467174</td>\n",
       "      <td>0.177570</td>\n",
       "      <td>0.512643</td>\n",
       "      <td>0.110266</td>\n",
       "      <td>0.147246</td>\n",
       "      <td>0.899076</td>\n",
       "      <td>0.361177</td>\n",
       "      <td>0.361177</td>\n",
       "      <td>0.367094</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016736</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.177654</td>\n",
       "      <td>0.195569</td>\n",
       "      <td>0.227758</td>\n",
       "      <td>0.139367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622575</td>\n",
       "      <td>0.380685</td>\n",
       "      <td>0.427168</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>0.617585</td>\n",
       "      <td>0.241192</td>\n",
       "      <td>0.460505</td>\n",
       "      <td>0.460505</td>\n",
       "      <td>0.550734</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.983264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.273810</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.389978</td>\n",
       "      <td>0.282569</td>\n",
       "      <td>0.164698</td>\n",
       "      <td>0.237409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506349</td>\n",
       "      <td>0.419364</td>\n",
       "      <td>0.515360</td>\n",
       "      <td>0.293080</td>\n",
       "      <td>0.263963</td>\n",
       "      <td>0.566979</td>\n",
       "      <td>0.568377</td>\n",
       "      <td>0.568377</td>\n",
       "      <td>0.623859</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.987448</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>0.037203</td>\n",
       "      <td>0.091503</td>\n",
       "      <td>0.380734</td>\n",
       "      <td>0.384460</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455246</td>\n",
       "      <td>0.066528</td>\n",
       "      <td>0.234069</td>\n",
       "      <td>0.097540</td>\n",
       "      <td>0.281215</td>\n",
       "      <td>0.426243</td>\n",
       "      <td>0.741069</td>\n",
       "      <td>0.741069</td>\n",
       "      <td>0.387643</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.991632</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048029</td>\n",
       "      <td>0.129751</td>\n",
       "      <td>0.642202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592211</td>\n",
       "      <td>0.281358</td>\n",
       "      <td>0.521021</td>\n",
       "      <td>0.352350</td>\n",
       "      <td>0.582677</td>\n",
       "      <td>0.812008</td>\n",
       "      <td>0.687372</td>\n",
       "      <td>0.687372</td>\n",
       "      <td>0.242686</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.519841</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.578794</td>\n",
       "      <td>0.144954</td>\n",
       "      <td>0.189306</td>\n",
       "      <td>0.194554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305626</td>\n",
       "      <td>0.095886</td>\n",
       "      <td>0.388076</td>\n",
       "      <td>0.464801</td>\n",
       "      <td>0.698401</td>\n",
       "      <td>0.698401</td>\n",
       "      <td>0.143949</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.237473</td>\n",
       "      <td>0.132110</td>\n",
       "      <td>0.240751</td>\n",
       "      <td>0.436061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633193</td>\n",
       "      <td>0.210672</td>\n",
       "      <td>0.457310</td>\n",
       "      <td>0.629851</td>\n",
       "      <td>0.412823</td>\n",
       "      <td>0.466606</td>\n",
       "      <td>0.616404</td>\n",
       "      <td>0.616404</td>\n",
       "      <td>0.293511</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id     DESPC     DESSC     DESWC     DESPL    DESPLd    DESPLw  \\\n",
       "0    0.000000  0.666667  0.000000  0.187192  0.000000  0.000000  0.103911   \n",
       "1    0.004184  0.333333  0.272727  0.325123  0.125000  0.272727  0.157542   \n",
       "2    0.008368  0.333333  0.363636  0.354680  0.166667  0.363636  0.177654   \n",
       "3    0.012552  0.333333  0.272727  0.394089  0.125000  0.272727  0.197765   \n",
       "4    0.016736  0.333333  0.454545  0.379310  0.208333  0.454545  0.177654   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "475  0.983264  0.000000  0.176471  0.273810  0.207547  0.176471  0.389978   \n",
       "476  0.987448  0.857143  0.117647  0.250000  0.015094  0.037203  0.091503   \n",
       "477  0.991632  0.285714  0.000000  0.103175  0.000000  0.048029  0.129751   \n",
       "478  0.995816  0.000000  0.470588  0.519841  0.490566  0.352941  0.578794   \n",
       "479  1.000000  0.000000  0.176471  0.111111  0.207547  0.058824  0.237473   \n",
       "\n",
       "        DESSL    DESSLd   DESWLsy  ...  WORD_PROPERTY_WRDHYPn  \\\n",
       "0    0.903743  0.000000  1.000000  ...               0.244583   \n",
       "1    0.331016  0.509944  0.109532  ...               0.267995   \n",
       "2    0.254011  0.442546  0.199330  ...               0.471208   \n",
       "3    0.398396  0.388716  0.191279  ...               0.467174   \n",
       "4    0.195569  0.227758  0.139367  ...               0.622575   \n",
       "..        ...       ...       ...  ...                    ...   \n",
       "475  0.282569  0.164698  0.237409  ...               0.506349   \n",
       "476  0.380734  0.384460  0.002353  ...               0.455246   \n",
       "477  0.642202  0.000000  0.353339  ...               0.592211   \n",
       "478  0.144954  0.189306  0.194554  ...               0.492107   \n",
       "479  0.132110  0.240751  0.436061  ...               0.633193   \n",
       "\n",
       "     WORD_PROPERTY_WRDHYPv  WORD_PROPERTY_WRDHYPnv  WORD_PROPERTY_AOA  \\\n",
       "0                 0.283489                0.388215           0.687937   \n",
       "1                 0.338908                0.076927           0.051748   \n",
       "2                 0.183434                0.469044           0.238065   \n",
       "3                 0.177570                0.512643           0.110266   \n",
       "4                 0.380685                0.427168           0.267677   \n",
       "..                     ...                     ...                ...   \n",
       "475               0.419364                0.515360           0.293080   \n",
       "476               0.066528                0.234069           0.097540   \n",
       "477               0.281358                0.521021           0.352350   \n",
       "478               0.000000                0.305626           0.095886   \n",
       "479               0.210672                0.457310           0.629851   \n",
       "\n",
       "     WORD_PROPERTY_AOA_MAX  WORD_PROPERTY_CONCRETENESS  \\\n",
       "0                 0.396186                    0.434696   \n",
       "1                 0.309322                    0.676325   \n",
       "2                 0.297608                    0.756879   \n",
       "3                 0.147246                    0.899076   \n",
       "4                 0.617585                    0.241192   \n",
       "..                     ...                         ...   \n",
       "475               0.263963                    0.566979   \n",
       "476               0.281215                    0.426243   \n",
       "477               0.582677                    0.812008   \n",
       "478               0.388076                    0.464801   \n",
       "479               0.412823                    0.466606   \n",
       "\n",
       "     WORD_PROPERTY_PREVALENCE  WORD_PROPERTY_PREVALENCE_MIN  \\\n",
       "0                    0.637852                      0.637852   \n",
       "1                    0.646687                      0.646687   \n",
       "2                    0.615946                      0.615946   \n",
       "3                    0.361177                      0.361177   \n",
       "4                    0.460505                      0.460505   \n",
       "..                        ...                           ...   \n",
       "475                  0.568377                      0.568377   \n",
       "476                  0.741069                      0.741069   \n",
       "477                  0.687372                      0.687372   \n",
       "478                  0.698401                      0.698401   \n",
       "479                  0.616404                      0.616404   \n",
       "\n",
       "     WORD_SET_INCIDENCE_C4_COMMON_WORDS  Polarity  \n",
       "0                              0.685198      Fake  \n",
       "1                              0.252618      Fake  \n",
       "2                              0.546360      Fake  \n",
       "3                              0.367094      Fake  \n",
       "4                              0.550734      Fake  \n",
       "..                                  ...       ...  \n",
       "475                            0.623859      True  \n",
       "476                            0.387643      True  \n",
       "477                            0.242686      True  \n",
       "478                            0.143949      True  \n",
       "479                            0.293511      True  \n",
       "\n",
       "[480 rows x 64 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fts = all_fts.drop(labels=\"id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 63)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_fts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESPC', 'DESSC', 'DESWC', 'DESPL', 'DESPLd', 'DESPLw', 'DESSL', 'DESSLd', 'DESWLsy', 'DESWLsyd', 'DESWLlt', 'DESWLltd', 'LDTTRc', 'LDTTRa', 'LDMTLD', 'LDHDD', 'SYNLE', 'SYNNP', 'SYNMEDpos', 'SYNMEDwrd', 'SYNMEDlem', 'SYNSTRUTa', 'SYNSTRUTt', 'RDFRE', 'READFKGL', 'TOKEN_ATTRIBUTE_RATIO_ALHPA', 'TOKEN_ATTRIBUTE_RATIO_DIGIT', 'TOKEN_ATTRIBUTE_RATIO_PUNCT', 'TOKEN_ATTRIBUTE_RATIO_URL', 'TOKEN_ATTRIBUTE_RATIO_EMAIL', 'WORD_SET_INCIDENCE_WRDPRP1s', 'WORD_SET_INCIDENCE_WRDPRP1p', 'WORD_SET_INCIDENCE_WRDPRP2', 'WORD_SET_INCIDENCE_WRDPRP3s', 'WORD_SET_INCIDENCE_WRDPRP3p', 'WORD_SET_INCIDENCE_CNCCaus', 'WORD_SET_INCIDENCE_CNCLogic', 'WORD_SET_INCIDENCE_CNCTemp', 'WORD_SET_INCIDENCE_CNCAdd', 'WORD_SET_INCIDENCE_CNCPos', 'WORD_SET_INCIDENCE_CNCNeg', 'WORD_PROPERTY_WRDNOUN', 'WORD_PROPERTY_WRDVERB', 'WORD_PROPERTY_WRDADJ', 'WORD_PROPERTY_WRDADV', 'WORD_PROPERTY_WRDFRQc', 'WORD_PROPERTY_WRDFRQa', 'WORD_PROPERTY_WRDFRQmc', 'WORD_PROPERTY_WRDFAMc', 'WORD_PROPERTY_WRDCNCc', 'WORD_PROPERTY_WRDIMGc', 'WORD_PROPERTY_WRDMEAc', 'WORD_PROPERTY_WRDPOLc', 'WORD_PROPERTY_WRDHYPn', 'WORD_PROPERTY_WRDHYPv', 'WORD_PROPERTY_WRDHYPnv', 'WORD_PROPERTY_AOA', 'WORD_PROPERTY_AOA_MAX', 'WORD_PROPERTY_CONCRETENESS', 'WORD_PROPERTY_PREVALENCE', 'WORD_PROPERTY_PREVALENCE_MIN', 'WORD_SET_INCIDENCE_C4_COMMON_WORDS', 'Polarity']\n"
     ]
    }
   ],
   "source": [
    "features = list(all_fts.columns)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DESPC': 0, 'DESSC': 0, 'DESWC': 0, 'DESPL': 0, 'DESPLd': 30, 'DESPLw': 0, 'DESSL': 0, 'DESSLd': 0, 'DESWLsy': 0, 'DESWLsyd': 0, 'DESWLlt': 0, 'DESWLltd': 0, 'LDTTRc': 0, 'LDTTRa': 0, 'LDMTLD': 0, 'LDHDD': 0, 'SYNLE': 0, 'SYNNP': 0, 'SYNMEDpos': 0, 'SYNMEDwrd': 0, 'SYNMEDlem': 0, 'SYNSTRUTa': 0, 'SYNSTRUTt': 480, 'RDFRE': 0, 'READFKGL': 0, 'TOKEN_ATTRIBUTE_RATIO_ALHPA': 0, 'TOKEN_ATTRIBUTE_RATIO_DIGIT': 0, 'TOKEN_ATTRIBUTE_RATIO_PUNCT': 0, 'TOKEN_ATTRIBUTE_RATIO_URL': 0, 'TOKEN_ATTRIBUTE_RATIO_EMAIL': 480, 'WORD_SET_INCIDENCE_WRDPRP1s': 0, 'WORD_SET_INCIDENCE_WRDPRP1p': 0, 'WORD_SET_INCIDENCE_WRDPRP2': 0, 'WORD_SET_INCIDENCE_WRDPRP3s': 0, 'WORD_SET_INCIDENCE_WRDPRP3p': 0, 'WORD_SET_INCIDENCE_CNCCaus': 0, 'WORD_SET_INCIDENCE_CNCLogic': 0, 'WORD_SET_INCIDENCE_CNCTemp': 0, 'WORD_SET_INCIDENCE_CNCAdd': 0, 'WORD_SET_INCIDENCE_CNCPos': 0, 'WORD_SET_INCIDENCE_CNCNeg': 0, 'WORD_PROPERTY_WRDNOUN': 0, 'WORD_PROPERTY_WRDVERB': 0, 'WORD_PROPERTY_WRDADJ': 0, 'WORD_PROPERTY_WRDADV': 0, 'WORD_PROPERTY_WRDFRQc': 0, 'WORD_PROPERTY_WRDFRQa': 0, 'WORD_PROPERTY_WRDFRQmc': 0, 'WORD_PROPERTY_WRDFAMc': 0, 'WORD_PROPERTY_WRDCNCc': 0, 'WORD_PROPERTY_WRDIMGc': 0, 'WORD_PROPERTY_WRDMEAc': 0, 'WORD_PROPERTY_WRDPOLc': 0, 'WORD_PROPERTY_WRDHYPn': 0, 'WORD_PROPERTY_WRDHYPv': 0, 'WORD_PROPERTY_WRDHYPnv': 0, 'WORD_PROPERTY_AOA': 0, 'WORD_PROPERTY_AOA_MAX': 0, 'WORD_PROPERTY_CONCRETENESS': 0, 'WORD_PROPERTY_PREVALENCE': 0, 'WORD_PROPERTY_PREVALENCE_MIN': 0, 'WORD_SET_INCIDENCE_C4_COMMON_WORDS': 0, 'Polarity': 0}\n"
     ]
    }
   ],
   "source": [
    "nan_dict = {}\n",
    "for col in all_fts:\n",
    "    nan_dict[col] = all_fts[col].isna().sum()\n",
    "print(nan_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in nan_dict:\n",
    "    if nan_dict[k] > 0:\n",
    "        all_fts = all_fts.drop(labels=k, axis = 1)\n",
    "\n",
    "data = all_fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESPC', 'DESSC', 'DESWC', 'DESPL', 'DESPLw', 'DESSL', 'DESSLd', 'DESWLsy', 'DESWLsyd', 'DESWLlt', 'DESWLltd', 'LDTTRc', 'LDTTRa', 'LDMTLD', 'LDHDD', 'SYNLE', 'SYNNP', 'SYNMEDpos', 'SYNMEDwrd', 'SYNMEDlem', 'SYNSTRUTa', 'RDFRE', 'READFKGL', 'TOKEN_ATTRIBUTE_RATIO_ALHPA', 'TOKEN_ATTRIBUTE_RATIO_DIGIT', 'TOKEN_ATTRIBUTE_RATIO_PUNCT', 'TOKEN_ATTRIBUTE_RATIO_URL', 'WORD_SET_INCIDENCE_WRDPRP1s', 'WORD_SET_INCIDENCE_WRDPRP1p', 'WORD_SET_INCIDENCE_WRDPRP2', 'WORD_SET_INCIDENCE_WRDPRP3s', 'WORD_SET_INCIDENCE_WRDPRP3p', 'WORD_SET_INCIDENCE_CNCCaus', 'WORD_SET_INCIDENCE_CNCLogic', 'WORD_SET_INCIDENCE_CNCTemp', 'WORD_SET_INCIDENCE_CNCAdd', 'WORD_SET_INCIDENCE_CNCPos', 'WORD_SET_INCIDENCE_CNCNeg', 'WORD_PROPERTY_WRDNOUN', 'WORD_PROPERTY_WRDVERB', 'WORD_PROPERTY_WRDADJ', 'WORD_PROPERTY_WRDADV', 'WORD_PROPERTY_WRDFRQc', 'WORD_PROPERTY_WRDFRQa', 'WORD_PROPERTY_WRDFRQmc', 'WORD_PROPERTY_WRDFAMc', 'WORD_PROPERTY_WRDCNCc', 'WORD_PROPERTY_WRDIMGc', 'WORD_PROPERTY_WRDMEAc', 'WORD_PROPERTY_WRDPOLc', 'WORD_PROPERTY_WRDHYPn', 'WORD_PROPERTY_WRDHYPv', 'WORD_PROPERTY_WRDHYPnv', 'WORD_PROPERTY_AOA', 'WORD_PROPERTY_AOA_MAX', 'WORD_PROPERTY_CONCRETENESS', 'WORD_PROPERTY_PREVALENCE', 'WORD_PROPERTY_PREVALENCE_MIN', 'WORD_SET_INCIDENCE_C4_COMMON_WORDS', 'Polarity']\n"
     ]
    }
   ],
   "source": [
    "features = list(all_fts.columns)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [LogisticRegression()]\n",
    "\n",
    "models = [KNeighborsClassifier(), RandomForestClassifier()]\n",
    "\n",
    "# models = [SVC(kernel =\"linear\")]\n",
    "\n",
    "# models = [LogisticRegression(), SVC(kernel =\"linear\"), KNeighborsClassifier(), RandomForestClassifier()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique Polairty labels: [0 1]\n",
      "Info: 60 features were passed at the fit step\n",
      ":\n",
      "DESPC\n",
      "DESSC\n",
      "DESWC\n",
      "DESPL\n",
      "DESPLw\n",
      "DESSL\n",
      "DESSLd\n",
      "DESWLsy\n",
      "DESWLsyd\n",
      "DESWLlt\n",
      "DESWLltd\n",
      "LDTTRc\n",
      "LDTTRa\n",
      "LDMTLD\n",
      "LDHDD\n",
      "SYNLE\n",
      "SYNNP\n",
      "SYNMEDpos\n",
      "SYNMEDwrd\n",
      "SYNMEDlem\n",
      "SYNSTRUTa\n",
      "RDFRE\n",
      "READFKGL\n",
      "TOKEN_ATTRIBUTE_RATIO_ALHPA\n",
      "TOKEN_ATTRIBUTE_RATIO_DIGIT\n",
      "TOKEN_ATTRIBUTE_RATIO_PUNCT\n",
      "TOKEN_ATTRIBUTE_RATIO_URL\n",
      "WORD_SET_INCIDENCE_WRDPRP1s\n",
      "WORD_SET_INCIDENCE_WRDPRP1p\n",
      "WORD_SET_INCIDENCE_WRDPRP2\n",
      "WORD_SET_INCIDENCE_WRDPRP3s\n",
      "WORD_SET_INCIDENCE_WRDPRP3p\n",
      "WORD_SET_INCIDENCE_CNCCaus\n",
      "WORD_SET_INCIDENCE_CNCLogic\n",
      "WORD_SET_INCIDENCE_CNCTemp\n",
      "WORD_SET_INCIDENCE_CNCAdd\n",
      "WORD_SET_INCIDENCE_CNCPos\n",
      "WORD_SET_INCIDENCE_CNCNeg\n",
      "WORD_PROPERTY_WRDNOUN\n",
      "WORD_PROPERTY_WRDVERB\n",
      "WORD_PROPERTY_WRDADJ\n",
      "WORD_PROPERTY_WRDADV\n",
      "WORD_PROPERTY_WRDFRQc\n",
      "WORD_PROPERTY_WRDFRQa\n",
      "WORD_PROPERTY_WRDFRQmc\n",
      "WORD_PROPERTY_WRDFAMc\n",
      "WORD_PROPERTY_WRDCNCc\n",
      "WORD_PROPERTY_WRDIMGc\n",
      "WORD_PROPERTY_WRDMEAc\n",
      "WORD_PROPERTY_WRDPOLc\n",
      "WORD_PROPERTY_WRDHYPn\n",
      "WORD_PROPERTY_WRDHYPv\n",
      "WORD_PROPERTY_WRDHYPnv\n",
      "WORD_PROPERTY_AOA\n",
      "WORD_PROPERTY_AOA_MAX\n",
      "WORD_PROPERTY_CONCRETENESS\n",
      "WORD_PROPERTY_PREVALENCE\n",
      "WORD_PROPERTY_PREVALENCE_MIN\n",
      "WORD_SET_INCIDENCE_C4_COMMON_WORDS\n",
      "Polarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_15788\\769299175.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.Polarity[data.Polarity == 'Fake'] = 0\n",
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_15788\\769299175.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.Polarity[data.Polarity == 'True'] = 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m   \u001b[38;5;28mprint\u001b[39m(feature)\n\u001b[0;32m     24\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:390\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    384\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSum of y is not strictly positive which \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis necessary for Poisson regression.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    386\u001b[0m         )\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 390\u001b[0m y, expanded_class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_y_class_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m!=\u001b[39m DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mcontiguous:\n\u001b[0;32m    393\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(y, dtype\u001b[38;5;241m=\u001b[39mDOUBLE)\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:749\u001b[0m, in \u001b[0;36mForestClassifier._validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_y_class_weight\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[1;32m--> 749\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(y)\n\u001b[0;32m    752\u001b[0m     expanded_class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:216\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    208\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    215\u001b[0m ]:\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "if data.Polarity[0] != 0 or 1:\n",
    "  data.Polarity[data.Polarity == 'Fake'] = 0\n",
    "  data.Polarity[data.Polarity == 'True'] = 1\n",
    "\n",
    "outcomes = [\"Fake\",\"Real\"]\n",
    "print(\"unique Polairty labels:\", data.Polarity.unique())\n",
    "  \n",
    "data = all_fts\n",
    "feature_cols = features\n",
    "\n",
    "X = data[feature_cols]\n",
    "y = data.Polarity #outcomes 0 or 1\n",
    "\n",
    "lab = preprocessing.LabelEncoder()\n",
    "y_transformed = lab.fit_transform(y)\n",
    "\n",
    "print(\"Info: {} features were passed at the fit step\\n:\".format(X.shape[1]))\n",
    "for feature in feature_cols:\n",
    "  print(feature)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=16)\n",
    "\n",
    "model = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list_dicts =[]\n",
    "\n",
    "for model in models:\n",
    "  \n",
    "  model = model.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  model_name = str(model)[:-2]\n",
    "\n",
    "  if model_name == \"SVC(kernel=\\'linear\":\n",
    "\n",
    "    model_name = \"SVC\"\n",
    "\n",
    "  model_dict = {}\n",
    "\n",
    "  ft_str = str(features)[2:-2].replace(\"'\",\"_\").replace(\",\", \"_\").replace(\" \", \"_\").replace(\"___\", \"_\")\n",
    "\n",
    "  model_dict[\"name\"] = ft_str + \"__\" + model_name\n",
    "\n",
    "  model_dict[\"features\"] = features\n",
    "\n",
    "  model_dict[\"model\"] = model_name\n",
    "\n",
    "  print(\"\\n\",model_name, \"\\n\", \"\\n\")\n",
    "\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "  model_dict[\"accuracy\"] = accuracy\n",
    "\n",
    "  print(\"OVERALL ACCURACY\", model_name, \":\", round(accuracy*100, 2),\"%\"\"\\n\")\n",
    "  \n",
    "  \n",
    "  scores = class_report(y_test, y_pred)\n",
    "\n",
    "  model_dict[\"report\"] = scores\n",
    "\n",
    "  print(\"\\n\")\n",
    "\n",
    "  \n",
    "  cv_score = cross_val_score(model, X, y, cv = 5)\n",
    "  print(\"Accuracy {} for each of the 5 iterations:\".format(model_name))\n",
    "  for score in cv_score:\n",
    "  print(round(score*100, 2), \"%\")\n",
    "\n",
    "  mean_accuracy = sum(cv_score)/len(cv_score)\n",
    "\n",
    "  model_dict[\"cv_scores\"] = cv_score\n",
    "\n",
    "  model_dict[\"mean_cv_accuracy\"] = mean_accuracy\n",
    "\n",
    "  print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "  print(\"\\nCross validation mean accuracy for {}:\".format(model_name), round(mean_accuracy*100, 2),\"%\")\n",
    "  print(\"\\n-------------------------------------------------------------------------\\n\")\n",
    "\n",
    "  confussion_matrix = conf_matrix(model_name, features, y_pred, y_test, cmap=\"magma\")\n",
    "\n",
    "  model_dict[\"confussion_matrix\"] = confussion_matrix\n",
    "\n",
    "  model_list_dicts.append(model_dict)\n",
    "  \n",
    "# def class_report(y_test, y_pred):\n",
    "\n",
    "#   outcomes = [\"Fake\",\"Real\"]\n",
    "\n",
    "#   scores = classification_report(y_test, y_pred, target_names=outcomes)\n",
    "\n",
    "#   print(scores)\n",
    "\n",
    "#   return scores\n",
    "\n",
    "# model_name = str(model)[:-2]\n",
    "\n",
    "# if model_name == \"SVC(kernel=\\'linear\":\n",
    "\n",
    "#   model_name = \"SVC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_15788\\121798834.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.Polarity[data.Polarity == 'Fake'] = 0\n",
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_15788\\121798834.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.Polarity[data.Polarity == 'True'] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: 60 features were passed at the fit step\n",
      ":\n",
      "DESPC\n",
      "DESSC\n",
      "DESWC\n",
      "DESPL\n",
      "DESPLw\n",
      "DESSL\n",
      "DESSLd\n",
      "DESWLsy\n",
      "DESWLsyd\n",
      "DESWLlt\n",
      "DESWLltd\n",
      "LDTTRc\n",
      "LDTTRa\n",
      "LDMTLD\n",
      "LDHDD\n",
      "SYNLE\n",
      "SYNNP\n",
      "SYNMEDpos\n",
      "SYNMEDwrd\n",
      "SYNMEDlem\n",
      "SYNSTRUTa\n",
      "RDFRE\n",
      "READFKGL\n",
      "TOKEN_ATTRIBUTE_RATIO_ALHPA\n",
      "TOKEN_ATTRIBUTE_RATIO_DIGIT\n",
      "TOKEN_ATTRIBUTE_RATIO_PUNCT\n",
      "TOKEN_ATTRIBUTE_RATIO_URL\n",
      "WORD_SET_INCIDENCE_WRDPRP1s\n",
      "WORD_SET_INCIDENCE_WRDPRP1p\n",
      "WORD_SET_INCIDENCE_WRDPRP2\n",
      "WORD_SET_INCIDENCE_WRDPRP3s\n",
      "WORD_SET_INCIDENCE_WRDPRP3p\n",
      "WORD_SET_INCIDENCE_CNCCaus\n",
      "WORD_SET_INCIDENCE_CNCLogic\n",
      "WORD_SET_INCIDENCE_CNCTemp\n",
      "WORD_SET_INCIDENCE_CNCAdd\n",
      "WORD_SET_INCIDENCE_CNCPos\n",
      "WORD_SET_INCIDENCE_CNCNeg\n",
      "WORD_PROPERTY_WRDNOUN\n",
      "WORD_PROPERTY_WRDVERB\n",
      "WORD_PROPERTY_WRDADJ\n",
      "WORD_PROPERTY_WRDADV\n",
      "WORD_PROPERTY_WRDFRQc\n",
      "WORD_PROPERTY_WRDFRQa\n",
      "WORD_PROPERTY_WRDFRQmc\n",
      "WORD_PROPERTY_WRDFAMc\n",
      "WORD_PROPERTY_WRDCNCc\n",
      "WORD_PROPERTY_WRDIMGc\n",
      "WORD_PROPERTY_WRDMEAc\n",
      "WORD_PROPERTY_WRDPOLc\n",
      "WORD_PROPERTY_WRDHYPn\n",
      "WORD_PROPERTY_WRDHYPv\n",
      "WORD_PROPERTY_WRDHYPnv\n",
      "WORD_PROPERTY_AOA\n",
      "WORD_PROPERTY_AOA_MAX\n",
      "WORD_PROPERTY_CONCRETENESS\n",
      "WORD_PROPERTY_PREVALENCE\n",
      "WORD_PROPERTY_PREVALENCE_MIN\n",
      "WORD_SET_INCIDENCE_C4_COMMON_WORDS\n",
      "Polarity\n",
      "\n",
      " LogisticRegression \n",
      " \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmagic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_fts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[46], line 222\u001b[0m, in \u001b[0;36mmagic\u001b[1;34m(data, features)\u001b[0m\n\u001b[0;32m    218\u001b[0m data, outcomes \u001b[38;5;241m=\u001b[39m data_preprocess(data) \u001b[38;5;66;03m# data in the correct format for the y outcomes\u001b[39;00m\n\u001b[0;32m    220\u001b[0m X, y, X_train, X_test, y_train, y_test, features, y_ref \u001b[38;5;241m=\u001b[39m test_train(data, features) \u001b[38;5;66;03m# here we have the data split for all the models with the desired features\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m model_list_dicts \u001b[38;5;241m=\u001b[39m \u001b[43mcompare_models_train_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ref\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# for each model it will compute\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_list_dicts\n",
      "Cell \u001b[1;32mIn[46], line 168\u001b[0m, in \u001b[0;36mcompare_models_train_test_split\u001b[1;34m(models, X, y, X_train, y_train, X_test, y_test, features, y_ref)\u001b[0m\n\u001b[0;32m    164\u001b[0m model_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model_name\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,model_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 168\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m    172\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1216\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m   1208\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1209\u001b[0m     X,\n\u001b[0;32m   1210\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1215\u001b[0m )\n\u001b[1;32m-> 1216\u001b[0m \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[0;32m   1219\u001b[0m multi_class \u001b[38;5;241m=\u001b[39m _check_multi_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class, solver, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_))\n",
      "File \u001b[1;32mc:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:216\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    208\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    215\u001b[0m ]:\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "# magic(all_fts, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(features)\n",
    "\n",
    "confussion_matrix = confusion_matrix(y_pred, y_test)\n",
    "\n",
    "outcomes = [\"Fake\",\"Real\"]\n",
    "ticks = np.arange(len(outcomes))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.xticks(ticks, outcomes)\n",
    "plt.yticks(ticks, outcomes)\n",
    "sns.heatmap(pd.DataFrame(confussion_matrix), annot=True, cmap=cmap, fmt=\"g\", xticklabels=outcomes, yticklabels=outcomes)\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.ylabel(\"Actual label\")\n",
    "plt.xlabel(\"Predicted label\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
